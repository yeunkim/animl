{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "sys.path.append('/usr/local/cuda/lib64')\n",
    "sys.path.append('/usr/local/lib/python2.7/dist-packages/')\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages/')\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .......\n",
      "Solving package specifications: ..........\n",
      "\n",
      "Package plan for installation in environment /root/miniconda3/envs/carnd-term1:\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    xlrd-1.1.0                 |           py35_0         169 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    xlrd: 1.1.0-py35_0\n",
      "\n",
      "Fetching packages ...\n",
      "xlrd-1.1.0-py3 100% |################################| Time: 0:00:00  19.11 MB/s\n",
      "Extracting packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n",
      "Linking packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "demographics = pd.read_excel('/src/Data/ANIML/oasis_cross-sectional.xls', sheetname=3) # load data\n",
    "df = demographics.dropna(how='any') # remove NaN values\n",
    "df_columns = list(demographics.columns)\n",
    "X_columns = np.delete(df_columns, [6,7], None) # X matrix won't have MMSE or CDR scores\n",
    "Xdf = df.reindex(columns=X_columns)\n",
    "X = Xdf.values # creating X\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# Define function to get list of pngs based on slice number\n",
    "pngs_path='/src/Data/ANIML/OASIS_pngs'\n",
    "def getaxialPNG(path):\n",
    "    l = []\n",
    "    axialslice90_files = []\n",
    "    axialslice91_files = []\n",
    "    axialslice92_files = []\n",
    "    axialslice93_files = []\n",
    "    axialslice94_files = []\n",
    "    axialslice95_files = []\n",
    "    axialslice96_files = []\n",
    "    axialslice97_files = []\n",
    "    axialslice98_files = []\n",
    "    axialslice99_files = []\n",
    "    \n",
    "    for root, directories, filenames in os.walk(path):\n",
    "        \n",
    "        for filename in filenames:\n",
    "            if \".90.\" in filename: \n",
    "                axialslice90_files.append(os.path.join(root, filename))\n",
    "            if \".91.\" in filename: \n",
    "                axialslice91_files.append(os.path.join(root, filename))\n",
    "            if \".92.\" in filename: \n",
    "                axialslice92_files.append(os.path.join(root, filename))\n",
    "            if \".93.\" in filename: \n",
    "                axialslice93_files.append(os.path.join(root, filename))\n",
    "            if \".94.\" in filename: \n",
    "                axialslice94_files.append(os.path.join(root, filename))\n",
    "            if \".95.\" in filename: \n",
    "                axialslice95_files.append(os.path.join(root, filename))\n",
    "            if \".96.\" in filename: \n",
    "                axialslice96_files.append(os.path.join(root, filename))\n",
    "            if \".97.\" in filename: \n",
    "                axialslice97_files.append(os.path.join(root, filename))\n",
    "            if \".98.\" in filename: \n",
    "                axialslice98_files.append(os.path.join(root, filename))\n",
    "            if \".99.\" in filename: \n",
    "                axialslice99_files.append(os.path.join(root, filename))\n",
    "\n",
    "    l = list(zip(axialslice90_files, axialslice91_files, axialslice92_files, axialslice93_files, axialslice94_files, axialslice95_files, axialslice96_files, axialslice97_files, axialslice98_files, axialslice99_files))\n",
    "\n",
    "    return ((np.asarray(l)))\n",
    "\n",
    "axial_files0 = getaxialPNG(pngs_path)\n",
    "axial_X_files = np.take(axial_files0, indices=df.index.values, axis=0) # keeps the images with the same index as X matrix\n",
    "axial90loc, axial91loc, axial92loc, axial93loc, axial94loc, axial95loc, axial96loc, axial97loc, axial98loc, axial99loc = zip(*axial_X_files)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "X_id, X_sex, X_handedness, X_age, X_education, X_SES, X_eTIV, X_nWBV, X_ASF = zip(*X) # unzips big X matrix\n",
    "\n",
    "def sex_translator(X_sex):\n",
    "    X_sex_binary = []\n",
    "    X_sex_encoded = []\n",
    "    for x in X_sex:\n",
    "        if x == 'M':\n",
    "            X_sex_binary.append(1)\n",
    "            X_sex_encoded.append([0,1])\n",
    "        else:\n",
    "            X_sex_binary.append(-1)\n",
    "            X_sex_encoded.append([1,0])\n",
    "    \n",
    "    return(zip(X_sex_binary, X_sex_encoded)) # gives us binary and one-hot encoded for sex\n",
    "           \n",
    "def hand_translator(X_handedness):\n",
    "    X_hand_binary = []\n",
    "    X_hand_encoded = []\n",
    "    for x in X_handedness:\n",
    "        if x == 'R':\n",
    "            X_hand_binary.append(1)\n",
    "            X_hand_encoded.append([0,1])\n",
    "        else:\n",
    "            X_hand_binary.append(-1)\n",
    "            X_hand_encoded.append([1,0])\n",
    "    \n",
    "    return(zip(X_hand_binary, X_hand_encoded)) # same as above but for handedness\n",
    "\n",
    "# turns out all the patients are right-handed\n",
    "# maybe we should all just be left-handed so we don't suffer from Alzheimer's\n",
    "# /frequentist sarcasm\n",
    "\n",
    "X_sex_binary, X_sex_encoded = zip(*sex_translator(X_sex)) # unzipping to get our function outputs\n",
    "X_hand_binary, X_hand_encoded = zip(*hand_translator(X_handedness))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def prepPNGimgs(array_of_image_paths):\n",
    "    l = []\n",
    "    for img_file in array_of_image_paths: # for each file in the list of images...\n",
    "        img = cv2.imread(\"{}\".format(img_file)) # read the image...\n",
    "        img = cv2.resize(np.array(img), (224,224)) # resize it to 224 by 224 QUICK WHAT'S 224 SQUARED??\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # makes it grayscale\n",
    "        flatten = gray.flatten() # spaghettifies it into 1 by 50176 (which is 224 squared)\n",
    "        l.append(flatten)\n",
    "    \n",
    "    return(np.asarray(l))\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "Y_CDR_columns = [column_name for column_name in df_columns if column_name == 'CDR']\n",
    "Y_CDR_df = df.reindex(columns=Y_CDR_columns)\n",
    "Y_CDR = Y_CDR_df.values\n",
    "\n",
    "Y_MMSE_columns = [column_name for column_name in df_columns if column_name == 'MMSE']\n",
    "Y_MMSE_df = df.reindex(columns=Y_MMSE_columns)\n",
    "Y_MMSE = Y_MMSE_df.values\n",
    "\n",
    "CDR_threshold_0 = 0 # threshold values by CDR scale\n",
    "CDR_threshold_0point5 = 0.5\n",
    "CDR_threshold_1 = 1\n",
    "\n",
    "MMSE_threshold_24 = 24 # threshold values by MMSE scale\n",
    "MMSE_threshold_18 = 18\n",
    "\n",
    "def CDR_probable_AD_thresholder(Y_CDR, threshold_value):\n",
    "    Y_CDR_binary = []\n",
    "    Y_CDR_encoded = []\n",
    "    for y in Y_CDR:\n",
    "        if y > threshold_value:\n",
    "            Y_CDR_binary.append(1)\n",
    "            Y_CDR_encoded.append([0,1])\n",
    "        else:\n",
    "            Y_CDR_binary.append(-1)\n",
    "            Y_CDR_encoded.append([1,0])\n",
    "\n",
    "    return((zip(Y_CDR_binary, Y_CDR_encoded)))\n",
    "\n",
    "def MMSE_probable_Dementia_thresholder(Y_MMSE, threshold_value):\n",
    "    Y_MMSE_binary = []\n",
    "    Y_MMSE_encoded = []\n",
    "    for y in Y_MMSE:\n",
    "        if y < threshold_value:\n",
    "            Y_MMSE_binary.append(1)\n",
    "            Y_MMSE_encoded.append([0,1])\n",
    "        else:\n",
    "            Y_MMSE_binary.append(-1)\n",
    "            Y_MMSE_encoded.append([1,0])\n",
    "        \n",
    "    return(zip(Y_MMSE_binary, Y_MMSE_encoded))\n",
    "\n",
    "Y_CDR_binary, Y_CDR_encoded = zip(*CDR_probable_AD_thresholder(Y_CDR, CDR_threshold_0))\n",
    "Y_MMSE_binary, Y_MMSE_encoded = zip(*MMSE_probable_Dementia_thresholder(Y_MMSE, MMSE_threshold_24))\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "# turning everything into numpy arrays because why not\n",
    "\n",
    "df_index = np.asarray(df.index.values)\n",
    "X_id = np.asarray(X_id)\n",
    "X_sex = np.asarray(X_sex)\n",
    "X_sex_binary = np.asarray(X_sex_binary)\n",
    "X_sex_encoded = np.asarray(X_sex_encoded)\n",
    "X_handedness = np.asarray(X_handedness)\n",
    "X_hand_binary = np.asarray(X_hand_binary)\n",
    "X_hand_encoded = np.asarray(X_hand_encoded)\n",
    "X_age = np.asarray(X_age) \n",
    "X_education = np.asarray(X_education) \n",
    "X_SES = np.asarray(X_SES)\n",
    "X_eTIV = np.asarray(X_eTIV)\n",
    "X_nWBV = np.asarray(X_nWBV)\n",
    "X_ASF = np.asarray(X_ASF)\n",
    "axial90loc = np.asarray(axial90loc) \n",
    "axial91loc = np.asarray(axial91loc)\n",
    "axial92loc = np.asarray(axial92loc) \n",
    "axial93loc = np.asarray(axial93loc)\n",
    "axial94loc = np.asarray(axial94loc)\n",
    "axial95loc = np.asarray(axial95loc) \n",
    "axial96loc = np.asarray(axial96loc) \n",
    "axial97loc = np.asarray(axial97loc) \n",
    "axial98loc = np.asarray(axial98loc) \n",
    "axial99loc = np.asarray(axial99loc)\n",
    "axial90_spaghetti = prepPNGimgs(axial90loc)\n",
    "axial91_spaghetti = prepPNGimgs(axial91loc)\n",
    "axial92_spaghetti = prepPNGimgs(axial92loc)\n",
    "axial93_spaghetti = prepPNGimgs(axial93loc)\n",
    "axial94_spaghetti = prepPNGimgs(axial94loc)\n",
    "axial95_spaghetti = prepPNGimgs(axial95loc)\n",
    "axial96_spaghetti = prepPNGimgs(axial96loc)\n",
    "axial97_spaghetti = prepPNGimgs(axial97loc)\n",
    "axial98_spaghetti = prepPNGimgs(axial98loc)\n",
    "axial99_spaghetti = prepPNGimgs(axial99loc)\n",
    "Y_CDR = np.squeeze(np.asarray(Y_CDR))\n",
    "Y_CDR_binary = np.asarray(Y_CDR_binary)\n",
    "Y_CDR_encoded = np.asarray(Y_CDR_encoded)\n",
    "Y_MMSE = np.squeeze(np.asarray(Y_MMSE))\n",
    "Y_MMSE_binary = np.asarray(Y_MMSE_binary)\n",
    "Y_MMSE_encoded = np.asarray(Y_MMSE_encoded)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "FinalX = np.vstack((X_id, X_sex, X_sex_binary, X_handedness, X_hand_binary, X_age, X_education, X_SES, X_eTIV, X_nWBV, X_ASF))\n",
    "FinalX = FinalX.T\n",
    "\n",
    "FinalY = np.vstack((Y_CDR, Y_CDR_binary, Y_MMSE, Y_MMSE_binary))\n",
    "FinalY = FinalY.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating and then turning them into dataframes then into CSVs\n",
    "\n",
    "XDATAFRAME = pd.DataFrame((FinalX), index=df_index, columns=['X_id', 'X_sex', 'X_sex_binary', 'X_handedness', 'X_hand_binary', 'X_age', 'X_education', 'X_SES', 'X_eTIV', 'X_nWBV', 'X_ASF'])\n",
    "\n",
    "YDATAFRAME = pd.DataFrame((FinalY), index=df_index, columns=['Y_CDR', 'Y_CDR_binary', 'Y_MMSE', 'Y_MMSE_binary'])\n",
    "\n",
    "classifiers = pd.DataFrame((Y_CDR_encoded), index=df_index, columns=['NC','AD'])\n",
    "\n",
    "# NeuralNetDF = pd.concat([axial90s, ouput], axis=1)\n",
    "\n",
    "# XDATAFRAME.to_csv('Data/ANIML/X_DataFrame.csv')\n",
    "# YDATAFRAME.to_csv('Data/ANIML/Y_DataFrame.csv')\n",
    "# NeuralNetDF.to_csv('Data/ANIML/NN_Data_frame_90.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axial90s = pd.concat([pd.DataFrame((axial90_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial91s = pd.concat([pd.DataFrame((axial91_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial92s = pd.concat([pd.DataFrame((axial92_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial93s = pd.concat([pd.DataFrame((axial93_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial94s = pd.concat([pd.DataFrame((axial94_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial95s = pd.concat([pd.DataFrame((axial95_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial96s = pd.concat([pd.DataFrame((axial96_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial97s = pd.concat([pd.DataFrame((axial97_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial98s = pd.concat([pd.DataFrame((axial98_spaghetti), index=df_index), classifiers], axis=1)\n",
    "axial99s = pd.concat([pd.DataFrame((axial99_spaghetti), index=df_index), classifiers], axis=1)\n",
    "\n",
    "# axial91s = pd.DataFrame((axial91_spaghetti), index=df_index)\n",
    "# axial92s = pd.DataFrame((axial92_spaghetti), index=df_index)\n",
    "# axial93s = pd.DataFrame((axial93_spaghetti), index=df_index)\n",
    "# axial94s = pd.DataFrame((axial94_spaghetti), index=df_index)\n",
    "# axial95s = pd.DataFrame((axial95_spaghetti), index=df_index)\n",
    "# axial96s = pd.DataFrame((axial96_spaghetti), index=df_index)\n",
    "# axial97s = pd.DataFrame((axial97_spaghetti), index=df_index)\n",
    "# axial98s = pd.DataFrame((axial98_spaghetti), index=df_index)\n",
    "# axial99s = pd.DataFrame((axial99_spaghetti), index=df_index)\n",
    "\n",
    "allSlices = pd.concat([axial90s, axial91s, axial93s, axial94s, axial95s, axial96s, axial97s, axial98s, axial99s],axis=0)\n",
    "\n",
    "#shuffle rows\n",
    "allSlicesShuff = allSlices.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "X_train0 = allSlicesShuff.drop(['NC', 'AD'], axis=1)[0:1000].as_matrix()\n",
    "y_train0 = allSlicesShuff['AD'][0:1000].as_matrix()\n",
    "\n",
    "X_test0 = allSlicesShuff.drop(['NC', 'AD'], axis=1)[1000:].as_matrix()\n",
    "y_test0 = allSlicesShuff['AD'][1000:].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = X_train0, y_train0, X_test0, y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNetMnistClassifier():\n",
    "    @staticmethod\n",
    "    def toDigit(hot_encode):\n",
    "        return np.argmax(hot_encode)\n",
    "        \n",
    "    def __init__(self, **kwargs):\n",
    "        if kwargs.get(\"model_path\", None):\n",
    "            from keras.models import load_model\n",
    "            self.model = load_model(kwargs['model_path'])\n",
    "        else:\n",
    "            self.activation_function = kwargs.pop('activation_function', 'relu')\n",
    "            self.batch_size = kwargs.pop('batch_size', 128)\n",
    "            self.epochs = kwargs.pop('epochs', 5)\n",
    "            self.kernal_size = kwargs.pop('kernal_size', (3, 3))\n",
    "            self.loss_function = kwargs.pop('loss_function', 'categorical_crossentropy')\n",
    "            self.optimizer = kwargs.pop('optimizer', 'sgd')\n",
    "            self.pool_size = kwargs.pop('pool_size', (2, 2))\n",
    "            self.model = self._model()\n",
    "            \n",
    "    \n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=self.kernal_size, padding='same',\n",
    "                 activation=self.activation_function,\n",
    "                 input_shape=(224,224,1)))\n",
    "        # One additional convolutional layer (32 channels)\n",
    "        model.add(Conv2D(32, kernel_size=self.kernal_size, padding='same',\n",
    "                 activation=self.activation_function))\n",
    "        model.add(Conv2D(32, kernel_size=self.kernal_size, padding='same',\n",
    "                 activation=self.activation_function))\n",
    "        model.add(MaxPooling2D(pool_size=self.pool_size))\n",
    "        model.add(Conv2D(64, self.kernal_size, padding='same', activation=self.activation_function))\n",
    "        # One additional convolutional layer (64 channels)\n",
    "        model.add(Conv2D(64, self.kernal_size, padding='same', activation=self.activation_function))\n",
    "        model.add(Conv2D(64, self.kernal_size, padding='same', activation=self.activation_function))\n",
    "        model.add(MaxPooling2D(pool_size=self.pool_size))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation=self.activation_function))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, digits=()):\n",
    "        return self.model.predict(digits)\n",
    "    \n",
    "    def evaluate(self, X_test=None, y_test=None):\n",
    "        X_test = X_test.reshape(X_test.shape[0], 224, 224, 1)\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_test/=255        \n",
    "        number_of_classes = 2\n",
    "        y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "    \n",
    "    def preprocess_and_train(self, X_train=None, y_train=None, X_test=None, y_test=None):\n",
    "        self._train(*self._preprocess(X_train, y_train, X_test, y_test))\n",
    "        \n",
    "    def _preprocess(self, X_train, y_train, X_test, y_test):\n",
    "        X_train = X_train.reshape(X_train.shape[0], 224, 224, 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], 224, 224, 1)\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        \n",
    "        X_train/=255\n",
    "        X_test/=255\n",
    "        \n",
    "        number_of_classes = 2\n",
    "        y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "        y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def _train(self, X_train, y_train, X_test, y_test):\n",
    "        self.model.compile(loss=self.loss_function,\n",
    "              optimizer=self.optimizer,\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "        fit_output = self.model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=self.batch_size,\n",
    "                        epochs=self.epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, y_test))\n",
    "        self._history = fit_output.history\n",
    "        \n",
    "        import time\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.model.save(\"oasis_test_{0}.h5\".format(timestr)) \n",
    "    \n",
    "    @property\n",
    "    def history(self):\n",
    "        return self._history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 944 samples\n",
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 0.6926 - acc: 0.5490 - val_loss: 0.6913 - val_acc: 0.6250\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 0.6824 - acc: 0.6070 - val_loss: 0.6781 - val_acc: 0.6250\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 0.6758 - acc: 0.6070 - val_loss: 0.6975 - val_acc: 0.6250\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 0.6676 - acc: 0.6070 - val_loss: 0.6696 - val_acc: 0.6250\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6721 - acc: 0.6070 - val_loss: 0.6624 - val_acc: 0.6250\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 255s 255ms/step - loss: 0.6744 - acc: 0.6070 - val_loss: 0.6632 - val_acc: 0.6250\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6752 - acc: 0.6070 - val_loss: 0.6732 - val_acc: 0.6250\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 255s 255ms/step - loss: 0.6783 - acc: 0.6070 - val_loss: 0.6790 - val_acc: 0.6250\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6754 - acc: 0.6070 - val_loss: 0.6639 - val_acc: 0.6250\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6743 - acc: 0.6070 - val_loss: 0.6692 - val_acc: 0.6250\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 0.6733 - acc: 0.6070 - val_loss: 0.6626 - val_acc: 0.6250\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 0.6738 - acc: 0.6070 - val_loss: 0.6627 - val_acc: 0.6250\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 0.6702 - acc: 0.6070 - val_loss: 0.6615 - val_acc: 0.6250\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 255s 255ms/step - loss: 0.6738 - acc: 0.6070 - val_loss: 0.6662 - val_acc: 0.6250\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 0.6714 - acc: 0.6070 - val_loss: 0.6713 - val_acc: 0.6250\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6713 - acc: 0.6070 - val_loss: 0.6612 - val_acc: 0.6250\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6710 - acc: 0.6070 - val_loss: 0.6617 - val_acc: 0.6250\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 255s 255ms/step - loss: 0.6728 - acc: 0.6070 - val_loss: 0.6612 - val_acc: 0.6250\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 0.6715 - acc: 0.6070 - val_loss: 0.6640 - val_acc: 0.6250\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 257s 257ms/step - loss: 0.6709 - acc: 0.6070 - val_loss: 0.6625 - val_acc: 0.6250\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 0.6724 - acc: 0.6070 - val_loss: 0.6627 - val_acc: 0.6250\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6732 - acc: 0.6070 - val_loss: 0.6623 - val_acc: 0.6250\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6743 - acc: 0.6070 - val_loss: 0.6617 - val_acc: 0.6250\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 254s 254ms/step - loss: 0.6700 - acc: 0.6070 - val_loss: 0.6643 - val_acc: 0.6250\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 0.6724 - acc: 0.6070 - val_loss: 0.6612 - val_acc: 0.6250\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 0.6707 - acc: 0.6070 - val_loss: 0.6621 - val_acc: 0.6250\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - 256s 256ms/step - loss: 0.6691 - acc: 0.6070 - val_loss: 0.6601 - val_acc: 0.6250\n",
      "Epoch 28/30\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 0.6722 - acc: 0.6070 - val_loss: 0.6610 - val_acc: 0.6250\n",
      "Epoch 29/30\n",
      " 640/1000 [==================>...........] - ETA: 1:10 - loss: 0.6658 - acc: 0.6109"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-71d085bd8da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNetMnistClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b279b3b1eef0>\u001b[0m in \u001b[0;36mpreprocess_and_train\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b279b3b1eef0>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     83\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                         validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = LeNetMnistClassifier(epochs=30, optimizer=keras.optimizers.Adadelta())\n",
    "classifier.preprocess_and_train(X_train=X_train0, y_train=y_train0, X_test=X_test0, y_test=y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LeNetMnistClassifier()\n",
    "X_train1, y_train1, X_test1, y_test1 = classifier._preprocess(X_train0, y_train0, X_test0, y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 944 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 0.6714 - acc: 0.5940 - val_loss: 0.6771 - val_acc: 0.6250\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 0.6812 - acc: 0.6060 - val_loss: 0.6616 - val_acc: 0.6250\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 0.6686 - acc: 0.6090 - val_loss: 0.6585 - val_acc: 0.6250\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-84f3f17fadea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNetMnistClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b279b3b1eef0>\u001b[0m in \u001b[0;36mpreprocess_and_train\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b279b3b1eef0>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     83\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                         validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier2 = LeNetMnistClassifier(epochs=20, activation_function='elu')\n",
    "classifier2.preprocess_and_train(X_train=X_train0, y_train=y_train0, X_test=X_test0, y_test=y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(224, 224, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-95a3655e0a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    196\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 293\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    294\u001b[0m                 if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    295\u001b[0m                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(224, 224, 1)`"
     ]
    }
   ],
   "source": [
    "base_model= keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "features = base_model.predict(X_test1)\n",
    "features = features.reshape(images.shape[0], features.shape[1]*features.shape[2]*features.shape[3])\n",
    "\n",
    "loss_function='categorical_crossentropy'\n",
    "optimizer=keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "base_model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "fit_output = base_model.fit(X_train1,\n",
    "                        y_train1,\n",
    "                        batch_size=128,\n",
    "                        epochs=20,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test1, y_test1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
